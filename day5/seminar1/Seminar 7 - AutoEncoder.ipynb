{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA, Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import, load etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.333)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lfw_dataset import fetch_lfw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, attr = fetch_lfw_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32') / 256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        im = ax.imshow(X_train[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple start: PCA\n",
    "\n",
    "Just a cheat sheet:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/PCA_fish.png/256px-PCA_fish.png)\n",
    "\n",
    "- $n$ - number of objects;\n",
    "- $m$ - original dimensionality;\n",
    "- $d$ - target dimensionality;\n",
    "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
    "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
    "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
    "\n",
    "    $$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA = DenseLayer(activation=linear) -> DenseLayer(activation=linear)\n",
    "\n",
    "PCA can be seen as a special case of an Neural Network.\n",
    "\n",
    "Consider a dense layer with $d$ units:\n",
    "    $$\\mathrm{dense}(X) = f(X W + b)$$\n",
    "where:\n",
    "- $f$ - nonlinearity (sigmoid, $\\tanh$ etc);\n",
    "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix;\n",
    "- $W \\in \\mathrm{m \\times d}$, $b \\in \\mathbb{R}^d$ - layer's parameters;\n",
    "\n",
    "and PCA:\n",
    "   $$\\|(X W) \\hat{W} - X - \\mu\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
    "\n",
    "where:\n",
    "  - $W$ - orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Reshape, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pca():\n",
    "    inputs = Input(shape=(45, 45, 3))\n",
    "    \n",
    "    ### Dense layer can only accept 2D tensor,\n",
    "    ### so reshaping is done to flatten image tensor.\n",
    "    flatten = Reshape((45 * 45 * 3, ))(inputs)\n",
    "    \n",
    "    ###\n",
    "    ### your PCA here\n",
    "    ###\n",
    "    \n",
    "    shaped = Reshape((45, 45, 3))(decoded)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=shaped), Model(inputs=inputs, outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca, pca_encoder = make_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(pca, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adamax\n",
    "from keras.objectives import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.compile(optimizer=Adamax(lr=1.0e-3), loss=[MSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train, X_train, epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reco = pca.predict(X_test)\n",
    "code = pca_encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test MSE:', np.mean((X_reco - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 3\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, X_test.shape[0])\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 1)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_test[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 2)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_reco[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 3)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(code[k].reshape(8, 8), cmap=plt.cm.viridis)\n",
    "    cb = fig.colorbar(im)\n",
    "    if i == 0:\n",
    "        ax.set_title('Code')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending to AutoEncoder\n",
    "\n",
    "Just add more layers!\n",
    "\n",
    "![layers](https://pbs.twimg.com/media/CYggEo-VAAACg_n.png:small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Reshape, BatchNormalization\n",
    "from keras.activations import relu, elu, tanh\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.initializers import Orthogonal, glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_autoencoder():\n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-10\n",
    "    \n",
    "    inputs = Input(shape=(45, 45, 3))\n",
    "    flatten = Reshape((45 * 45 * 3, ))(inputs)\n",
    "    \n",
    "    ###\n",
    "    ### STACK MORE LAYERS here.\n",
    "    ###\n",
    "\n",
    "    shaped = Reshape((45, 45, 3), name='decoded')(decoded)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=shaped), Model(inputs=inputs, outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae, ae_encoder = make_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta\n",
    "from keras.objectives import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae.compile(optimizer=Adadelta(), loss=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(ae, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.fit(X_train, X_train, epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reco = ae.predict(X_test)\n",
    "code = ae_encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test MSE:', np.mean((X_reco - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 3\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, X_test.shape[0])\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 1)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_test[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 2)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_reco[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 3)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(code[k].reshape(8, 8), cmap=plt.cm.viridis)\n",
    "    cb = fig.colorbar(im)\n",
    "    if i == 0:\n",
    "        ax.set_title('Code')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images $\\Rightarrow$ convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Cropping2D\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.initializers import Orthogonal\n",
    "from keras.activations import relu\n",
    "from keras.losses import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conv_autoencoder():\n",
    "    inputs = Input(shape=(45, 45, 3))\n",
    "    net = inputs\n",
    "    \n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    \n",
    "    net = Conv2D(filters=32, kernel_size=(2, 2), activation=leaky_relu, padding='valid')(net)\n",
    "    net = MaxPooling2D()(net)\n",
    "    \n",
    "    ###\n",
    "    ### Please, convolve here.\n",
    "    ###\n",
    "    \n",
    "    net = UpSampling2D()(net)\n",
    "    net = Conv2DTranspose(filters = 3, kernel_size=(3, 3), activation='linear', padding='valid')(net)\n",
    "    \n",
    "    ### if resulting image is larger than the original\n",
    "    ### consider using cropping layer.\n",
    "    ### net = Cropping2D(cropping=((1, 0), (1, 0)))(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net), Model(inputs=inputs, outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cae, cae_encoder = make_conv_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cae, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Just for fun, let's see how MAE-based AE differs from MSE-based one.\n",
    "### Plus MAE contains AE...\n",
    "cae.compile(optimizer='adamax', loss=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae.fit(X_train, X_train, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reco = cae.predict(X_test)\n",
    "code = cae_encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test MSE:', np.mean((X_reco - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 3\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, X_test.shape[0])\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 1)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_test[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 2)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_reco[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 3)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(code[k].reshape(8, 8), cmap=plt.cm.viridis)\n",
    "    cb = fig.colorbar(im)\n",
    "    if i == 0:\n",
    "        ax.set_title('Code')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Convolutional Denoising AutoEncoder\n",
    "\n",
    "The idea behind denoising AutoEncoder is define behaviour of the AutoEncoder on points close to these from dataset:\n",
    "    $$\\left\\| \\mathrm{decode}(\\mathrm{encode}(X + \\varepsilon))) -X \\right\\|^2_2 \\to \\min$$\n",
    "    \n",
    "where:\n",
    "- $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2_\\varepsilon)$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, GaussianNoise, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Cropping2D\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.initializers import Orthogonal\n",
    "from keras.activations import relu\n",
    "from keras.losses import MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_denoising_conv_autoencoder(dropout_p = None, noise_stddev=0.1):\n",
    "    inputs = Input(shape=(45, 45, 3))\n",
    "    \n",
    "    leaky_relu = lambda x: relu(x, alpha=2.5e-2)\n",
    "    \n",
    "    noise = GaussianNoise(stddev=noise_stddev)(inputs)\n",
    "    \n",
    "    net = noise\n",
    "    \n",
    "    ###\n",
    "    ### Paste you fully convolution AutoEncoder here.\n",
    "    ###\n",
    "\n",
    "    net = Conv2DTranspose(filters = 3, kernel_size=(2, 2), activation='linear', padding='valid')(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcae = make_denoising_conv_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(dfcae, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcae.compile(optimizer='adamax', loss=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcae.fit(X_train, X_train, epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reco = dfcae.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean((X_reco - X_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 2\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, X_test.shape[0])\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 1)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_test[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 2)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_reco[k])\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus: cheap generative model\n",
    "\n",
    "A simple generative model (almost) is implemented below.\n",
    "\n",
    "See Bengio, Yoshua, et al. \"Deep generative stochastic networks trainable by backprop.\" International Conference on Machine Learning. 2014. for a more advanced method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_mnist_autoencoder(dropout_p = None, noise_stddev=0.1):\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    \n",
    "    leaky_relu = lambda x: relu(x, alpha=2.5e-2)\n",
    "    \n",
    "    noise = GaussianNoise(stddev=noise_stddev)(inputs)\n",
    "    \n",
    "    net = noise\n",
    "    \n",
    "    net = Conv2D(filters=16, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "    net = Conv2D(filters=32, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "    net = MaxPooling2D()(net)\n",
    "    ### apply dropout if dropout_p is not None\n",
    "    net = Dropout(dropout_p)(net) if dropout_p is not None else net\n",
    "    \n",
    "    net = Conv2D(filters=64, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "    net = MaxPooling2D()(net)\n",
    "    ### apply dropout if dropout_p is not None\n",
    "    net = Dropout(dropout_p)(net) if dropout_p is not None else net\n",
    "\n",
    "    net = Conv2D(filters=128, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "\n",
    "    net = Conv2DTranspose(filters = 128, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "    net = UpSampling2D()(net)\n",
    "    ### apply dropout if dropout_p is not None\n",
    "    net = Dropout(dropout_p)(net) if dropout_p is not None else net\n",
    "\n",
    "    net = Conv2DTranspose(filters = 32, kernel_size=(3, 3), activation=leaky_relu, padding='valid')(net)\n",
    "    net = UpSampling2D()(net)\n",
    "\n",
    "    net = Conv2DTranspose(filters = 16, kernel_size=(3, 3), activation='linear', padding='valid')(net)\n",
    "    net = Conv2DTranspose(filters = 1, kernel_size=(3, 3), activation='linear', padding='valid')(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_ae = make_mnist_autoencoder(dropout_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(mnist_ae, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_ae.compile(optimizer='adamax', loss=MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ae.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reco = mnist_ae.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 2\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, X_val.shape[0])\n",
    "\n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 1)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_val[k, :, :, 0], cmap=plt.cm.gray_r, vmin=0, vmax=1)\n",
    "    if i == 0:\n",
    "        ax.set_title('Original')\n",
    "    \n",
    "    ax = fig.add_subplot(rows, cols, i * cols + 2)\n",
    "    ax.grid('off')\n",
    "    im = ax.imshow(X_reco[k, :, :, 0], cmap=plt.cm.gray_r, vmin=0, vmax=1)\n",
    "    if i == 0:\n",
    "        ax.set_title('Reconstructed')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mcmc(X, steps = 16, return_each=4, stddev=0.1):\n",
    "    Xs = [X]\n",
    "    for i in range(steps // return_each):\n",
    "        for j in range(return_each):\n",
    "            X = mnist_ae.predict(X + np.random.normal(size=X.shape).astype('float32') * stddev)\n",
    "        \n",
    "        Xs.append(X)\n",
    "    \n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs = mcmc(X_test[:100], steps=256, return_each=32, stddev=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = len(Xs)\n",
    "rows = 10\n",
    "fig = plt.figure(figsize=(2.5 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(rows):\n",
    "    k = np.random.randint(0, Xs[0].shape[0])\n",
    "    \n",
    "    for j in range(cols):\n",
    "        ax = fig.add_subplot(rows, cols, i * cols + j + 1)\n",
    "        ax.grid('off')\n",
    "        im = ax.imshow(Xs[j][k, :, :, 0], cmap=plt.cm.gray_r, vmin=0, vmax=1)\n",
    "        if i == 0:\n",
    "            if j == 0:\n",
    "                ax.set_title('Original')\n",
    "            else:\n",
    "                ax.set_title('Step %d' % j)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
